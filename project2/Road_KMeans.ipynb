{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Road Safety Dataset\n",
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by Bernardo Augusto and Miguel Cisneiros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "from pyspark import SparkFiles\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "from pyspark.ml.feature import IndexToString, StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "import pyspark # Call this only after findspark.init()\n",
    "from pyspark.context import SparkContext\n",
    "from pyspark.sql.session import SparkSession\n",
    "\n",
    "sc = SparkContext.getOrCreate()\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------------+----------------------+---------+---------+------------+-----------------+------------------+--------------------+----------+-----------+-----+--------------------------+-------------------------+--------------+---------------+---------+-----------+---------------+----------------+--------------+---------------+---------------------------------+---------------------------------------+----------------+------------------+-----------------------+--------------------------+-------------------+-------------------+-------------------------------------------+-------------------------+\n",
      "|Accident_Index|Location_Easting_OSGR|Location_Northing_OSGR|Longitude| Latitude|Police_Force|Accident_Severity|Number_of_Vehicles|Number_of_Casualties|      Date|Day_of_Week| Time|Local_Authority_(District)|Local_Authority_(Highway)|1st_Road_Class|1st_Road_Number|Road_Type|Speed_limit|Junction_Detail|Junction_Control|2nd_Road_Class|2nd_Road_Number|Pedestrian_Crossing-Human_Control|Pedestrian_Crossing-Physical_Facilities|Light_Conditions|Weather_Conditions|Road_Surface_Conditions|Special_Conditions_at_Site|Carriageway_Hazards|Urban_or_Rural_Area|Did_Police_Officer_Attend_Scene_of_Accident|LSOA_of_Accident_Location|\n",
      "+--------------+---------------------+----------------------+---------+---------+------------+-----------------+------------------+--------------------+----------+-----------+-----+--------------------------+-------------------------+--------------+---------------+---------+-----------+---------------+----------------+--------------+---------------+---------------------------------+---------------------------------------+----------------+------------------+-----------------------+--------------------------+-------------------+-------------------+-------------------------------------------+-------------------------+\n",
      "| 2019010128300|               528218|                180407|-0.153842|51.508057|           1|                3|                 2|                   3|18/02/2019|          2|17:50|                         1|                E09000033|             3|           4202|        1|         30|              1|               2|             3|           4202|                                0|                                      5|               1|                 1|                      1|                         0|                  0|                  1|                                          3|                E01004762|\n",
      "| 2019010152270|               530219|                172463|-0.127949|51.436208|           1|                3|                 2|                   1|15/01/2019|          3|21:45|                         9|                E09000022|             3|             23|        2|         30|              0|              -1|            -1|              0|                               -1|                                     -1|               4|                 1|                      1|                         0|                  0|                  1|                                          3|                E01003117|\n",
      "| 2019010155191|               530222|                182543|-0.124193|51.526795|           1|                3|                 2|                   1|01/01/2019|          3|01:50|                         2|                E09000007|             4|            504|        6|         30|              3|               4|             6|              0|                                0|                                      0|               4|                 1|                      1|                         0|                  0|                  1|                                          1|                E01000943|\n",
      "| 2019010155192|               525531|                184605|-0.191044|51.546387|           1|                2|                 1|                   1|01/01/2019|          3|01:20|                         2|                E09000007|             4|            510|        6|         20|              3|               4|             4|            510|                                0|                                      0|               4|                 1|                      1|                         0|                  0|                  1|                                          1|                E01000973|\n",
      "| 2019010155194|               524920|                184004|-0.200064|51.541121|           1|                3|                 2|                   2|01/01/2019|          3|00:40|                        28|                E09000005|             3|           4003|        6|         30|              6|               4|             6|              0|                                0|                                      0|               4|                 1|                      1|                         0|                  0|                  1|                                          1|                E01000546|\n",
      "+--------------+---------------------+----------------------+---------+---------+------------+-----------------+------------------+--------------------+----------+-----------+-----+--------------------------+-------------------------+--------------+---------------+---------+-----------+---------------+----------------+--------------+---------------+---------------------------------+---------------------------------------+----------------+------------------+-----------------------+--------------------------+-------------------+-------------------+-------------------------------------------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "dataset = spark.read.csv(\"file://\"+ SparkFiles.get(\"/Users/bernardoaugusto/Desktop/3ยบ ano/1ยบ semestre/Big Data/Project/2/Road Safety Data - Accidents 2019.csv\"),header=True, sep=\",\", inferSchema=True)\n",
    "\n",
    "#show top 10 rows\n",
    "dataset.show(5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the -1 values from the spark dataset\n",
    "dataset = dataset.filter((dataset[\"Light_Conditions\"] != -1) & (dataset[\"Junction_Control\"] != -1) & (dataset[\"2nd_Road_Class\"] != -1)\n",
    "                        & (dataset[\"Pedestrian_Crossing-Human_Control\"] != -1) & (dataset[\"Pedestrian_Crossing-Physical_Facilities\"] != -1)\n",
    "                        & (dataset[\"Road_Surface_COnditions\"] != -1) & (dataset[\"Special_Conditions_at_Site\"] != -1)\n",
    "                        & (dataset[\"Carriageway_Hazards\"] != -1)\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Accident_Index: string, Location_Easting_OSGR: int, Location_Northing_OSGR: int, Longitude: double, Latitude: double, Police_Force: int, Accident_Severity: int, Number_of_Vehicles: int, Number_of_Casualties: int, Date: string, Day_of_Week: int, Time: string, Local_Authority_(District): int, Local_Authority_(Highway): string, 1st_Road_Class: int, 1st_Road_Number: int, Road_Type: int, Speed_limit: int, Junction_Detail: int, Junction_Control: int, 2nd_Road_Class: int, 2nd_Road_Number: int, Pedestrian_Crossing-Human_Control: int, Pedestrian_Crossing-Physical_Facilities: int, Light_Conditions: int, Weather_Conditions: int, Road_Surface_Conditions: int, Special_Conditions_at_Site: int, Carriageway_Hazards: int, Urban_or_Rural_Area: int, Did_Police_Officer_Attend_Scene_of_Accident: int, LSOA_of_Accident_Location: string]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.na.drop(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the indexes and the correlated variables\n",
    "dataset = dataset.drop(\"Accident_Index\", \"Location_Easting_OSGR\", \"Location_Northing_OSGR\", \"Police_Force\", \"LSOA_of_Accident_Location\", \n",
    "                      \"Local_Authority_(Highway)\", \"Time\", \"Date\", \"Longitude\", \"Latitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Accident_Severity: integer (nullable = true)\n",
      " |-- Number_of_Vehicles: integer (nullable = true)\n",
      " |-- Number_of_Casualties: integer (nullable = true)\n",
      " |-- Day_of_Week: integer (nullable = true)\n",
      " |-- Local_Authority_(District): integer (nullable = true)\n",
      " |-- 1st_Road_Class: integer (nullable = true)\n",
      " |-- 1st_Road_Number: integer (nullable = true)\n",
      " |-- Road_Type: integer (nullable = true)\n",
      " |-- Speed_limit: integer (nullable = true)\n",
      " |-- Junction_Detail: integer (nullable = true)\n",
      " |-- Junction_Control: integer (nullable = true)\n",
      " |-- 2nd_Road_Class: integer (nullable = true)\n",
      " |-- 2nd_Road_Number: integer (nullable = true)\n",
      " |-- Pedestrian_Crossing-Human_Control: integer (nullable = true)\n",
      " |-- Pedestrian_Crossing-Physical_Facilities: integer (nullable = true)\n",
      " |-- Light_Conditions: integer (nullable = true)\n",
      " |-- Weather_Conditions: integer (nullable = true)\n",
      " |-- Road_Surface_Conditions: integer (nullable = true)\n",
      " |-- Special_Conditions_at_Site: integer (nullable = true)\n",
      " |-- Carriageway_Hazards: integer (nullable = true)\n",
      " |-- Urban_or_Rural_Area: integer (nullable = true)\n",
      " |-- Did_Police_Officer_Attend_Scene_of_Accident: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema\n",
    "dataset.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1_col2 = dataset.groupBy(\"Accident_Severity\", \"Number_of_Casualties\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[Accident_Severity: int, Number_of_Casualties: int, count: bigint]\n"
     ]
    }
   ],
   "source": [
    "print(col1_col2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-----+----------+\n",
      "|Accident_Severity|Number_of_Casualties|count|  features|\n",
      "+-----------------+--------------------+-----+----------+\n",
      "|                3|                   1|40078| [3.0,1.0]|\n",
      "|                2|                   2| 1667| [2.0,2.0]|\n",
      "|                2|                  19|    1|[2.0,19.0]|\n",
      "|                1|                   7|    2| [1.0,7.0]|\n",
      "|                2|                   3|  528| [2.0,3.0]|\n",
      "+-----------------+--------------------+-----+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# transformer\n",
    "vector_assembler = VectorAssembler(inputCols=[\"Accident_Severity\",\n",
    "                                              \"Number_of_Casualties\"\n",
    "                                             ],outputCol=\"features\")\n",
    "output = vector_assembler.transform(col1_col2)\n",
    "output.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a k-means model.\n",
    "kmeans = KMeans().setK(2).setSeed(1)\n",
    "model = kmeans.fit(output.select(\"features\"))\n",
    "predictions = model.transform(output.select(\"features\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette with squared euclidean distance = 0.7674905938258503\n"
     ]
    }
   ],
   "source": [
    "# Evaluate clustering by computing Silhouette score\n",
    "evaluator = ClusteringEvaluator()\n",
    "silhouette = evaluator.evaluate(predictions)\n",
    "print(\"Silhouette with squared euclidean distance = \" + str(silhouette))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In my case, the silhouette score came out to be around 77% which is quite significant, explaining that the clusters are nicely spaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
